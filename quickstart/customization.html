

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Customization &mdash; cosmos-rl 0.1 documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=e59714d7" />

  
      <script src="../_static/jquery.js?v=5d32c60e"></script>
      <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../_static/documentation_options.js?v=2709fde1"></script>
      <script src="../_static/doctools.js?v=9bcbadda"></script>
      <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Multi-node example" href="../multinodes/overview.html" />
    <link rel="prev" title="Dataset &amp; Process" href="dataflow.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            cosmos-rl
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Quick Start</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="single_node_example.html">Single node example</a></li>
<li class="toctree-l1"><a class="reference internal" href="configuration.html">Configuration</a></li>
<li class="toctree-l1"><a class="reference internal" href="dataflow.html">Dataset &amp; Process</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Customization</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#customized-dataset">Customized dataset</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#how-to-tell-the-launcher-to-use-your-customized-dataset">How to tell the launcher to use your customized dataset?</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#customized-reward">Customized reward</a></li>
<li class="toctree-l2"><a class="reference internal" href="#customized-data-packer">Customized Data Packer</a></li>
<li class="toctree-l2"><a class="reference internal" href="#customized-model">Customized Model</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Multi nodes training</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../multinodes/overview.html">Multi-node example</a></li>
<li class="toctree-l1"><a class="reference internal" href="../multinodes/dgxc_lepton.html">DGXC-Lepton Job</a></li>
<li class="toctree-l1"><a class="reference internal" href="../multinodes/slurm.html">Slurm Job</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Elastic &amp; Fault Tolerance</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../elastic/overview.html">Elastic Scaling and Fault Tolerance</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Async RL</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../async/overview.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../async/overview.html#key-features">Key Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="../async/overview.html#architecture">Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="../async/overview.html#putting-it-all-together">Putting It All Together</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Parallelism</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../parallelism/overview.html">Parallelism</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">cosmos-rl</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Customization</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/quickstart/customization.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="customization">
<h1>Customization<a class="headerlink" href="#customization" title="Link to this heading"></a></h1>
<section id="customized-dataset">
<h2>Customized dataset<a class="headerlink" href="#customized-dataset" title="Link to this heading"></a></h2>
<p>A <cite>torch.utils.data.Dataset</cite> object with <cite>query_reference_answer</cite> method is all you need:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">CustomDataset</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">setup</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">Config</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">:</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">pass</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">query_reference_answer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Any</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Query the reference answer for reward computation.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="s2">&quot;reference_answer&quot;</span><span class="p">]</span>
</pre></div>
</div>
<p>Here we attach the <a class="reference external" href="https://huggingface.co/datasets/BytedTsinghua-SIA/DAPO-Math-17k">BytedTsinghua-SIA/DAPO-Math-17k</a> dataset as an example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Any</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Dict</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">Dataset</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">cosmos_rl.policy.config</span><span class="w"> </span><span class="kn">import</span> <span class="n">Config</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">cosmos_rl.dispatcher.algo.reward</span><span class="w"> </span><span class="kn">import</span> <span class="n">direct_math_reward_fn</span><span class="p">,</span> <span class="n">overlong_reward_fn</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">ConcatDataset</span>

<span class="k">class</span><span class="w"> </span><span class="nc">MathDapoDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">setup</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">Config</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">:</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        This method is optional and get called by launcher after being mounted</span>
<span class="sd">        `config`: config;</span>
<span class="sd">        `tokenizer`: tokenizer;</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span> <span class="o">=</span> <span class="n">config</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">tokenizer</span>

        <span class="c1"># This demo is only for DAPO-Math-17k dataset</span>
        <span class="k">assert</span> <span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">train_policy</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s2">&quot;BytedTsinghua-SIA/DAPO-Math-17k&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">train_policy</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">train_policy</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">subset</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        For DecoderOnlyLLMDataPacker, it should either return:</span>
<span class="sd">        - raw text prompt to be converted into input_ids by both rollout and policy models;</span>
<span class="sd">        - conversation format:</span>
<span class="sd">        ```</span>
<span class="sd">        [</span>
<span class="sd">            {</span>
<span class="sd">                &quot;role&quot;: &quot;system&quot;,</span>
<span class="sd">                &quot;content&quot;: &quot;You are an AI math expert, you will be given a question and required to answer. &quot;</span>
<span class="sd">            }</span>
<span class="sd">            ...</span>
<span class="sd">        ]</span>
<span class="sd">        ```</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="k">assert</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;tokenizer&quot;</span><span class="p">),</span> <span class="s2">&quot;`self.tokenizer` should be set by the launcher&quot;</span>
        <span class="n">conversation</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="s2">&quot;prompt&quot;</span><span class="p">]</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="n">conversation</span><span class="p">,</span> <span class="nb">list</span>
        <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;Prompt should be a string, but got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">conversation</span><span class="p">)</span><span class="si">}</span><span class="s2">， </span><span class="si">{</span><span class="n">conversation</span><span class="si">}</span><span class="s2">&quot;</span>

        <span class="c1"># Apply chat-template to get the raw prompt in text</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">apply_chat_template</span><span class="p">(</span>
            <span class="n">conversation</span><span class="p">,</span>
            <span class="n">tokenize</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">add_generation_prompt</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">get_reference_answer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        This is mandatory for GRPO to get a reference answer for reward computation.</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="s2">&quot;reward_model&quot;</span><span class="p">][</span><span class="s2">&quot;ground_truth&quot;</span><span class="p">]</span>
</pre></div>
</div>
<p>In this example, the dataset fetch each row and return the raw text prompt by applying chat-template. This demonstrates how user can customize the dataset to fit their needs.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>It is assumed here that decoder only LLM data packer is used, so we must either return the raw text prompt or the conversation format.</p>
</div>
<section id="how-to-tell-the-launcher-to-use-your-customized-dataset">
<h3>How to tell the launcher to use your customized dataset?<a class="headerlink" href="#how-to-tell-the-launcher-to-use-your-customized-dataset" title="Link to this heading"></a></h3>
<p>Since we have already defined our customized dataset in previous step, we need to override the launcher entry point to pass the custom dataset.</p>
<p>Save this file to <cite>./custom_entry.py</cite></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>   <span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Any</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Dict</span>
   <span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">Dataset</span>
   <span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span>
   <span class="kn">from</span><span class="w"> </span><span class="nn">cosmos_rl.launcher.worker_entry</span><span class="w"> </span><span class="kn">import</span> <span class="n">main</span> <span class="k">as</span> <span class="n">launch_worker</span>
   <span class="kn">from</span><span class="w"> </span><span class="nn">cosmos_rl.policy.config</span><span class="w"> </span><span class="kn">import</span> <span class="n">Config</span>
   <span class="kn">from</span><span class="w"> </span><span class="nn">cosmos_rl.dispatcher.algo.reward</span><span class="w"> </span><span class="kn">import</span> <span class="n">direct_math_reward_fn</span><span class="p">,</span> <span class="n">overlong_reward_fn</span>
   <span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span>
   <span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">ConcatDataset</span>

   <span class="k">class</span><span class="w"> </span><span class="nc">MathDapoDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
       <span class="o">...</span>

   <span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
       <span class="c1"># `dataset` argument can be:</span>
       <span class="c1">#   - a dataset instance</span>
       <span class="c1">#   - a factory function that returns a dataset instance</span>
       <span class="c1">#</span>
       <span class="c1"># It is best practice to pass the dataset as a factory function</span>
       <span class="c1"># so that the dataset can be loaded on demand. (Not all workers need it)</span>
       <span class="k">def</span><span class="w"> </span><span class="nf">get_dataset_factory</span><span class="p">(</span><span class="n">config</span><span class="p">:</span> <span class="n">Config</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dataset</span><span class="p">:</span>
           <span class="k">return</span> <span class="n">MathDapoDataset</span><span class="p">()</span>

       <span class="n">launch_worker</span><span class="p">(</span>
           <span class="n">dataset</span><span class="o">=</span><span class="n">get_dataset_factory</span><span class="p">,</span>
       <span class="p">)</span>


<span class="n">Append</span> <span class="n">your</span> <span class="n">customized</span> <span class="n">launcher</span> <span class="n">entry</span> <span class="n">point</span> <span class="n">to</span> <span class="err">`</span><span class="n">cosmos</span><span class="o">-</span><span class="n">rl</span><span class="err">`</span> <span class="n">command</span><span class="p">:</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">cosmos</span><span class="o">-</span><span class="n">rl</span> <span class="o">--</span><span class="n">config</span> <span class="n">configs</span><span class="o">/</span><span class="n">qwen3</span><span class="o">/</span><span class="n">qwen3</span><span class="o">-</span><span class="mi">8</span><span class="n">b</span><span class="o">-</span><span class="n">p</span><span class="o">-</span><span class="n">tp4</span><span class="o">-</span><span class="n">r</span><span class="o">-</span><span class="n">tp2</span><span class="o">-</span><span class="n">pp1</span><span class="o">-</span><span class="n">grpo</span><span class="o">.</span><span class="n">toml</span> \
<span class="go">    --policy 1 \</span>
<span class="go">    --rollout 2 \</span>
<span class="go">    custom_entry.py</span>
</pre></div>
</div>
<p>Check <a class="reference external" href="#">./tools/dataset/</a> for more pre-defined customized datasets.</p>
</section>
</section>
<section id="customized-reward">
<h2>Customized reward<a class="headerlink" href="#customized-reward" title="Link to this heading"></a></h2>
<p>Similar to customized dataset, override the launcher entry point to pass the custom reward functions:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="o">...</span>

<span class="k">def</span><span class="w"> </span><span class="nf">custom_reward_fn</span><span class="p">(</span><span class="n">to_be_evaluated</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">reference</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">reference</span><span class="p">,</span> <span class="nb">str</span><span class="p">),</span> <span class="s2">&quot;Reference answer should be a string&quot;</span>
    <span class="c1"># For demo purpose, we just return a random float</span>
    <span class="c1"># In practice, you should implement your own reward function</span>
    <span class="k">return</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">launch_worker</span><span class="p">(</span>
        <span class="c1">#...</span>
        <span class="n">reward_fns</span><span class="o">=</span><span class="p">[</span><span class="n">custom_reward_fn</span><span class="p">],</span>
        <span class="c1">#...</span>
    <span class="p">)</span>
</pre></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">to_be_evaluated</span></code>: rollout generation</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">reference</span></code>: reference answer from the dataset interface</p></li>
</ul>
<p>Final reward will be the sum of returned float values from all reward functions.</p>
</section>
<section id="customized-data-packer">
<h2>Customized Data Packer<a class="headerlink" href="#customized-data-packer" title="Link to this heading"></a></h2>
<p>Check <a class="reference external" href="#">decoder_only_llm_packer.py</a> to see how to implement a customized data packer for your own model.</p>
<p>Here we just reuse the pre-deined LLM data packer to demonstrate how to pass your data packer.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Any</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Dict</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">Dataset</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">cosmos_rl.launcher.worker_entry</span><span class="w"> </span><span class="kn">import</span> <span class="n">main</span> <span class="k">as</span> <span class="n">launch_worker</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">cosmos_rl.policy.config</span><span class="w"> </span><span class="kn">import</span> <span class="n">Config</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">cosmos_rl.dispatcher.algo.reward</span><span class="w"> </span><span class="kn">import</span> <span class="n">gsm8k_reward_fn</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">cosmos_rl.dispatcher.data.packer</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataPacker</span><span class="p">,</span> <span class="n">DecoderOnlyLLMDataPacker</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">cosmos_rl.utils.modelscope</span><span class="w"> </span><span class="kn">import</span> <span class="n">modelscope_load_dataset</span>

<span class="k">class</span><span class="w"> </span><span class="nc">GSM8kDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">setup</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">Config</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">:</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        This method is optional and get called by launcher after being mounted</span>
<span class="sd">        `config`: config;</span>
<span class="sd">        `tokenizer`: tokenizer;</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span> <span class="o">=</span> <span class="n">config</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">tokenizer</span>
        <span class="n">modelscope_dataset_if_enabled</span> <span class="o">=</span> <span class="n">modelscope_load_dataset</span><span class="p">(</span><span class="s1">&#39;AI-ModelScope/gsm8k&#39;</span><span class="p">,</span> <span class="n">subset_name</span><span class="o">=</span><span class="s1">&#39;main&#39;</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s1">&#39;train&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">modelscope_dataset_if_enabled</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;openai/gsm8k&quot;</span><span class="p">,</span> <span class="s2">&quot;main&quot;</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s2">&quot;train&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span> <span class="o">=</span> <span class="n">modelscope_dataset_if_enabled</span>


    <span class="k">def</span><span class="w"> </span><span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        For DecoderOnlyLLMDataPacker, it should either return:</span>
<span class="sd">        - raw text prompt to be converted into input_ids by both rollout and policy models;</span>
<span class="sd">        - conversation format:</span>
<span class="sd">        ```</span>
<span class="sd">        [</span>
<span class="sd">            {</span>
<span class="sd">                &quot;role&quot;: &quot;system&quot;,</span>
<span class="sd">                &quot;content&quot;: &quot;You are an AI math expert, you will be given a question and required to answer. &quot;</span>
<span class="sd">            }</span>
<span class="sd">            ...</span>
<span class="sd">        ]</span>
<span class="sd">        ```</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="k">assert</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;tokenizer&quot;</span><span class="p">),</span> <span class="s2">&quot;`self.tokenizer` should be set by the launcher&quot;</span>
        <span class="n">question</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="s2">&quot;question&quot;</span><span class="p">]</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="n">question</span><span class="p">,</span> <span class="nb">str</span>
        <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;Prompt should be a string, but got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">question</span><span class="p">)</span><span class="si">}</span><span class="s2">， </span><span class="si">{</span><span class="n">question</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="c1"># Convert to templated prompt</span>
        <span class="n">conversation</span> <span class="o">=</span> <span class="p">[</span>
            <span class="p">{</span>
                <span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;system&quot;</span><span class="p">,</span>
                <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;&quot;&quot;You are an AI math expert, you will be given a question and required to answer.</span>
<span class="s2">Final answer should be like</span>
<span class="s2">```</span>
<span class="s2">#### [ANS]</span>
<span class="s2">``` where [ANS] is your answer&quot;&quot;&quot;</span>
            <span class="p">},</span>
            <span class="p">{</span>
                <span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span>
                <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">question</span><span class="p">,</span>
            <span class="p">}</span>
        <span class="p">]</span>
        <span class="n">prompt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">apply_chat_template</span><span class="p">(</span>
            <span class="n">conversation</span><span class="p">,</span>
            <span class="n">tokenize</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">add_generation_prompt</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">prompt</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">get_reference_answer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        This is mandatory for GRPO to get a reference answer for reward computation.</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="s2">&quot;answer&quot;</span><span class="p">]</span>

<span class="k">class</span><span class="w"> </span><span class="nc">DemoDataPacker</span><span class="p">(</span><span class="n">DataPacker</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    This is a demo data packer that wraps the underlying data packer of the selected model.</span>
<span class="sd">    This is meaningless for this example, but useful for explaining:</span>
<span class="sd">        - how dataset data is processed and collated into a mini-batch for rollout engine;</span>
<span class="sd">        - how rollout output is processed and collated into a mini-batch for policy model;</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="c1"># Check source code of DecoderOnlyLLMDataPacker to see how it&#39;s implemented</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">underlying_data_packer</span> <span class="o">=</span> <span class="n">DecoderOnlyLLMDataPacker</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">setup</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">Config</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">:</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        This method is optional and get called by launcher after being mounted</span>
<span class="sd">        `config`: config;</span>
<span class="sd">        `tokenizer`: tokenizer;</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">setup</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">underlying_data_packer</span><span class="o">.</span><span class="n">setup</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">get_rollout_input</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">item</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Convert dataset item into what rollout engine (e.g. vllm) expects</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">underlying_data_packer</span><span class="o">.</span><span class="n">get_rollout_input</span><span class="p">(</span><span class="n">item</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">rollout_collate_fn</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">items</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Any</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Collate the rollout inputs into a mini-batch for rollout engine</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">underlying_data_packer</span><span class="o">.</span><span class="n">rollout_collate_fn</span><span class="p">(</span><span class="n">items</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">get_policy_input</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">item</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="n">rollout_output</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Process samples &amp; rollout output before collating them into a mini-batch</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">underlying_data_packer</span><span class="o">.</span><span class="n">get_policy_input</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="n">rollout_output</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">policy_compute_max_len</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">processed_samples</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Any</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Compute the maximum sequence length of the mini-batch</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">underlying_data_packer</span><span class="o">.</span><span class="n">policy_compute_max_len</span><span class="p">(</span><span class="n">processed_samples</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">policy_collate_fn</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">processed_samples</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Any</span><span class="p">],</span> <span class="n">computed_max_len</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Collate the mini-batch into the kwargs required by the policy model</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">underlying_data_packer</span><span class="o">.</span><span class="n">policy_collate_fn</span><span class="p">(</span><span class="n">processed_samples</span><span class="p">,</span> <span class="n">computed_max_len</span><span class="p">)</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">get_dataset_factory</span><span class="p">(</span><span class="n">config</span><span class="p">:</span> <span class="n">Config</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dataset</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">GSM8kDataset</span><span class="p">()</span>

    <span class="n">launch_worker</span><span class="p">(</span>
        <span class="c1">#...</span>
        <span class="n">dataset</span><span class="o">=</span><span class="n">get_dataset_factory</span><span class="p">,</span>
        <span class="n">data_packer</span><span class="o">=</span><span class="n">DemoDataPacker</span><span class="p">(),</span>
        <span class="c1">#...</span>
    <span class="p">)</span>
</pre></div>
</div>
</section>
<section id="customized-model">
<h2>Customized Model<a class="headerlink" href="#customized-model" title="Link to this heading"></a></h2>
<p>To customize the model, one needs to implement:</p>
<ul class="simple">
<li><p>A new model class that inherits from <cite>cosmos_rl.policy.model.base.BaseModel</cite></p></li>
<li><p>A <cite>WeightMapper</cite> class that inherits from <cite>cosmos_rl.policy.model.base.WeightMapper</cite></p></li>
<li><p>A <cite>DataPacker</cite> class that inherits from <cite>cosmos_rl.dispatcher.data.packer.DataPacker</cite></p></li>
</ul>
<p>Let’s take <cite>deepseek_v3</cite> as an example.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">cosmos_rl.launcher.worker_entry</span><span class="w"> </span><span class="kn">import</span> <span class="n">main</span> <span class="k">as</span> <span class="n">launch_worker</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">deepseek_v3</span><span class="w"> </span><span class="kn">import</span> <span class="n">DeepseekV3MoEModel</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">deepseek_v3.weight_mapper</span><span class="w"> </span><span class="kn">import</span> <span class="n">DeepseekV3MoEWeightMapper</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">cosmos_rl.dispatcher.data.packer.decoder_only_llm_data_packer</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">DecoderOnlyLLMDataPacker</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">cosmos_rl.policy.model.base</span><span class="w"> </span><span class="kn">import</span> <span class="n">ModelRegistry</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="c1"># Register the model into the registry</span>
    <span class="n">ModelRegistry</span><span class="o">.</span><span class="n">register_model</span><span class="p">(</span>
        <span class="c1"># Model class to register</span>
        <span class="n">DeepseekV3MoEModel</span><span class="p">,</span>
        <span class="c1"># Weight mapper for this model</span>
        <span class="n">DeepseekV3MoEWeightMapper</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">launch_worker</span><span class="p">()</span>
</pre></div>
</div>
<p>First import the model class, weight mapper class, and data packer class from the external source code.</p>
<p>Then register the model into the registry via <cite>ModelRegistry.register_model</cite>.</p>
<p>User can launch a external model job with:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">cosmos</span><span class="o">-</span><span class="n">rl</span> <span class="o">--</span><span class="n">config</span> <span class="o">./</span><span class="n">configs</span><span class="o">/</span><span class="n">deepseek</span><span class="o">-</span><span class="n">v3</span><span class="o">/</span><span class="n">moonlight</span><span class="o">-</span><span class="n">moe</span><span class="o">-</span><span class="mi">13</span><span class="n">b</span><span class="o">-</span><span class="n">tp4</span><span class="o">-</span><span class="n">sft</span><span class="o">.</span><span class="n">toml</span>
<span class="go">    ./tools/model/moonlight_launcher.py</span>
</pre></div>
</div>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="dataflow.html" class="btn btn-neutral float-left" title="Dataset &amp; Process" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../multinodes/overview.html" class="btn btn-neutral float-right" title="Multi-node example" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, NVIDIA.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>